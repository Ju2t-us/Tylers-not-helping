{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.reshape(image, [28, 28, 1])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\tyler\\tensorflow_datasets\\fashion_mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:21<00:00,  5.43s/ file]\n",
      "Dl Size...: 100%|██████████| 29/29 [00:21<00:00,  1.33 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:21<00:00,  5.43s/ url]\n",
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset fashion_mnist downloaded and prepared to C:\\Users\\tyler\\tensorflow_datasets\\fashion_mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess MNIST\n",
    "mnist_data = tfds.load('mnist', split=['train', 'test'], as_supervised=True)\n",
    "mnist_train = mnist_data[0].map(preprocess).batch(32).shuffle(1024)\n",
    "mnist_test = mnist_data[1].map(preprocess).batch(32)\n",
    "\n",
    "# Load and preprocess Fashion MNIST\n",
    "fashion_mnist_data = tfds.load('fashion_mnist', split=['train', 'test'], as_supervised=True)\n",
    "fashion_mnist_train = fashion_mnist_data[0].map(preprocess).batch(32).shuffle(1024)\n",
    "fashion_mnist_test = fashion_mnist_data[1].map(preprocess).batch(32)\n",
    "\n",
    "# Combine datasets\n",
    "combined_train = mnist_train.concatenate(fashion_mnist_train)\n",
    "combined_test = mnist_test.concatenate(fashion_mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tyler\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Building the CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.3473 - val_accuracy: 0.5328 - val_loss: 2.4897\n",
      "Epoch 2/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 5ms/step - accuracy: 0.9524 - loss: 0.1600 - val_accuracy: 0.7817 - val_loss: 0.7108\n",
      "Epoch 3/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9668 - loss: 0.1048 - val_accuracy: 0.8418 - val_loss: 0.5662\n",
      "Epoch 4/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 6ms/step - accuracy: 0.9715 - loss: 0.0863 - val_accuracy: 0.8693 - val_loss: 0.4502\n",
      "Epoch 5/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9742 - loss: 0.0764 - val_accuracy: 0.9128 - val_loss: 0.3016\n",
      "Epoch 6/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0706 - val_accuracy: 0.9201 - val_loss: 0.2757\n",
      "Epoch 7/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9799 - loss: 0.0604 - val_accuracy: 0.9251 - val_loss: 0.2701\n",
      "Epoch 8/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9802 - loss: 0.0578 - val_accuracy: 0.9369 - val_loss: 0.1999\n",
      "Epoch 9/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9823 - loss: 0.0523 - val_accuracy: 0.9363 - val_loss: 0.2055\n",
      "Epoch 10/10\n",
      "\u001b[1m3750/3750\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 6ms/step - accuracy: 0.9840 - loss: 0.0505 - val_accuracy: 0.9370 - val_loss: 0.2206\n",
      "\u001b[1m626/626\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9574 - loss: 0.1665\n",
      "\n",
      "Combined Test accuracy: 0.9369500279426575\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(combined_train, epochs=10, validation_data=combined_test)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(combined_test)\n",
    "print('\\nCombined Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
